{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNRtVYcqfWGtF4SWKWycJM2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["Importing and pre-processing"],"metadata":{"id":"kAbQz7_BhJFH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tuyl83iQ4tdp"},"outputs":[],"source":["%tensorflow_version 2.x  # this line is not required unless you are in a notebook\n","from keras.datasets import imdb\n","from keras.preprocessing import sequence\n","import keras\n","from tensorflow.keras.models import load_model\n","import tensorflow as tf\n","import os\n","import numpy as np\n","from keras.utils.data_utils import pad_sequences\n","\n","VOCAB_SIZE = 88584\n","\n","MAXLEN = 250\n","BATCH_SIZE = 64\n","\n","(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = VOCAB_SIZE)\n","\n","train_data = pad_sequences(train_data, MAXLEN)\n","test_data = pad_sequences(test_data, MAXLEN)"]},{"cell_type":"markdown","source":["Building the Model"],"metadata":{"id":"kUQAmeOuhWFu"}},{"cell_type":"code","source":["model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(VOCAB_SIZE, 32),\n","    tf.keras.layers.LSTM(32),\n","    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n","])"],"metadata":{"id":"QXKfhQd36NWO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(loss=\"binary_crossentropy\",optimizer=\"rmsprop\",metrics=['acc'])\n","\n","history = model.fit(train_data, train_labels, epochs=10, validation_split=0.2)\n","\n","results = model.evaluate(test_data, test_labels)\n","print(results)"],"metadata":{"id":"WKZyVq0O7I4G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Encoding and Decoding"],"metadata":{"id":"m-HwqN31hZVK"}},{"cell_type":"code","source":["word_index = imdb.get_word_index()\n","\n","def encode_text(text):\n","  tokens = keras.preprocessing.text.text_to_word_sequence(text)\n","  tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n","  return pad_sequences([tokens], MAXLEN)[0]\n","\n","text = \"that movie was just amazing, so amazing\"\n","encoded = encode_text(text)\n","print(encoded)"],"metadata":{"id":"1CagrMq9IOS7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# while were at it lets make a decode function\n","\n","reverse_word_index = {value: key for (key, value) in word_index.items()}\n","\n","def decode_integers(integers):\n","    PAD = 0\n","    text = \"\"\n","    for num in integers:\n","      if num != PAD:\n","        text += reverse_word_index[num] + \" \"\n","\n","    return text[:-1]\n","  \n","print(decode_integers(encoded))"],"metadata":{"id":"eGw81E3eKHzk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Testing "],"metadata":{"id":"s1XLef7vhdFr"}},{"cell_type":"code","source":["# now time to make a prediction\n","\n","def predict(text):\n","  encoded_text = encode_text(text)\n","  pred = np.zeros((1,250))\n","  pred[0] = encoded_text\n","  result = model.predict(pred) \n","  print(result[0])\n","\n","positive_review = \"That movie was! really loved it and would great watch it again because it was amazingly great\"\n","predict(positive_review)\n","\n","negative_review = \"that movie really sucked. I hated it and wouldn't watch it again. Was one of the worst things I've ever watched\"\n","predict(negative_review)"],"metadata":{"id":"ZS392iQbM58W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Saving the model"],"metadata":{"id":"hCGypevVhhaj"}},{"cell_type":"code","source":["# salvando em 2 arquivos (acima foi salvo em apenas um)\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n","# Salvar o classificador\n","model_json = model.to_json()\n","with open(\"/content/drive/MyDrive/model.json\", \"w\") as json_file:\n","    json_file.write(model_json)\n","model.save_weights(\"/content/drive/MyDrive/model.h5\")\n","\n"],"metadata":{"id":"z_uSNDyXT2xm"},"execution_count":null,"outputs":[]}]}